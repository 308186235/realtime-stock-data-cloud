#!/usr/bin/env python3
"""
é¡¹ç›®é…ç½®ä¿®å¤å·¥å…·
è‡ªåŠ¨ä¿®å¤Agentç­–ç•¥ã€å‰ç«¯é…ç½®å’Œéƒ¨ç½²é…ç½®çš„ä¸ä¸€è‡´é—®é¢˜
"""

import os
import json
import re
import shutil
import time
from pathlib import Path
from typing import Dict, List, Any

class ProjectConfigurationFixer:
    """é¡¹ç›®é…ç½®ä¿®å¤å™¨"""
    
    def __init__(self):
        self.root_dir = Path(".")
        self.backup_dir = Path(f"config_backup_{int(time.time())}")
        self.issues_found = []
        self.fixes_applied = []
        
        # ç»Ÿä¸€é…ç½®
        self.unified_config = {
            "api_base_url": "https://api.aigupiao.me",
            "ws_url": "wss://api.aigupiao.me/ws",
            "main_domain": "aigupiao.me",
            "app_domain": "app.aigupiao.me"
        }
        
    def run_comprehensive_fix(self):
        """è¿è¡Œç»¼åˆä¿®å¤"""
        print("ğŸ”§ å¼€å§‹é¡¹ç›®é…ç½®ç»¼åˆä¿®å¤...")
        print("=" * 50)
        
        try:
            # 1. åˆ›å»ºå¤‡ä»½
            self._create_backup()
            
            # 2. ä¿®å¤å‰ç«¯é…ç½®
            self._fix_frontend_configurations()
            
            # 3. ä¿®å¤Agentç­–ç•¥é…ç½®
            self._fix_agent_configurations()
            
            # 4. ä¿®å¤éƒ¨ç½²é…ç½®
            self._fix_deployment_configurations()
            
            # 5. æ¸…ç†é‡å¤æ–‡ä»¶
            self._cleanup_duplicate_files()
            
            # 6. ç”Ÿæˆä¿®å¤æŠ¥å‘Š
            self._generate_fix_report()
            
            print("\nğŸ‰ é¡¹ç›®é…ç½®ä¿®å¤å®Œæˆï¼")
            
        except Exception as e:
            print(f"\nâŒ ä¿®å¤è¿‡ç¨‹å‡ºé”™: {e}")
            self._restore_backup()
    
    def _create_backup(self):
        """åˆ›å»ºé…ç½®å¤‡ä»½"""
        print("ğŸ“„ åˆ›å»ºé…ç½®æ–‡ä»¶å¤‡ä»½...")
        
        self.backup_dir.mkdir(exist_ok=True)
        
        # å¤‡ä»½å…³é”®é…ç½®æ–‡ä»¶
        config_files = [
            "frontend/gupiao1/env.js",
            "frontend/stock5/env.js", 
            "ç‚’è‚¡å…»å®¶/env.js",
            "frontend/gupiao1/services/config.js",
            "ç‚’è‚¡å…»å®¶/services/config.js",
            "backend/app.py",
            "cloud_app.py"
        ]
        
        for file_path in config_files:
            if os.path.exists(file_path):
                backup_path = self.backup_dir / file_path
                backup_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, backup_path)
                print(f"âœ… å¤‡ä»½: {file_path}")
        
        print(f"ğŸ“ å¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def _fix_frontend_configurations(self):
        """ä¿®å¤å‰ç«¯é…ç½®"""
        print("\nğŸ¨ ä¿®å¤å‰ç«¯é…ç½®...")
        
        # å‰ç«¯é…ç½®æ–‡ä»¶åˆ—è¡¨
        frontend_configs = [
            {
                "path": "frontend/gupiao1/env.js",
                "name": "è‚¡ç¥¨1å‰ç«¯"
            },
            {
                "path": "frontend/stock5/env.js", 
                "name": "è‚¡ç¥¨5å‰ç«¯"
            },
            {
                "path": "ç‚’è‚¡å…»å®¶/env.js",
                "name": "ç‚’è‚¡å…»å®¶å‰ç«¯"
            }
        ]
        
        for config in frontend_configs:
            self._fix_single_frontend_config(config["path"], config["name"])
        
        # ä¿®å¤æœåŠ¡é…ç½®æ–‡ä»¶
        service_configs = [
            "frontend/gupiao1/services/config.js",
            "ç‚’è‚¡å…»å®¶/services/config.js"
        ]
        
        for config_path in service_configs:
            self._fix_service_config(config_path)
    
    def _fix_single_frontend_config(self, file_path: str, name: str):
        """ä¿®å¤å•ä¸ªå‰ç«¯é…ç½®æ–‡ä»¶"""
        if not os.path.exists(file_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return
        
        print(f"ğŸ”§ ä¿®å¤ {name}: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è®°å½•åŸå§‹é…ç½®
            original_dev_api = self._extract_api_url(content, 'DEV')
            original_prod_api = self._extract_api_url(content, 'PROD')
            
            if original_dev_api != self.unified_config["api_base_url"] or \
               original_prod_api != self.unified_config["api_base_url"]:
                
                self.issues_found.append({
                    "file": file_path,
                    "issue": f"APIåœ°å€ä¸ç»Ÿä¸€",
                    "original_dev": original_dev_api,
                    "original_prod": original_prod_api
                })
            
            # æ›¿æ¢å¼€å‘ç¯å¢ƒAPIåœ°å€
            content = re.sub(
                r"(// å¼€å‘ç¯å¢ƒ[\s\S]*?apiBaseUrl:\s*['\"])([^'\"]*)",
                f"\\1{self.unified_config['api_base_url']}",
                content
            )
            
            # æ›¿æ¢ç”Ÿäº§ç¯å¢ƒAPIåœ°å€
            content = re.sub(
                r"(// ç”Ÿäº§ç¯å¢ƒ[\s\S]*?apiBaseUrl:\s*['\"])([^'\"]*)",
                f"\\1{self.unified_config['api_base_url']}",
                content
            )
            
            # æ›¿æ¢WebSocketåœ°å€
            content = re.sub(
                r"(wsUrl:\s*['\"])([^'\"]*)",
                f"\\1{self.unified_config['ws_url']}",
                content
            )
            
            # å†™å…¥ä¿®å¤åçš„å†…å®¹
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.fixes_applied.append({
                "file": file_path,
                "action": "ç»Ÿä¸€APIåœ°å€é…ç½®",
                "new_api": self.unified_config["api_base_url"]
            })
            
            print(f"âœ… {name} é…ç½®å·²ä¿®å¤")
            
        except Exception as e:
            print(f"âŒ ä¿®å¤ {name} å¤±è´¥: {e}")
    
    def _extract_api_url(self, content: str, env_type: str) -> str:
        """æå–API URL"""
        pattern = f"// {env_type.lower()}ç¯å¢ƒ[\\s\\S]*?apiBaseUrl:\\s*['\"]([^'\"]*)"
        match = re.search(pattern, content)
        return match.group(1) if match else "æœªæ‰¾åˆ°"
    
    def _fix_service_config(self, file_path: str):
        """ä¿®å¤æœåŠ¡é…ç½®æ–‡ä»¶"""
        if not os.path.exists(file_path):
            return
        
        print(f"ğŸ”§ ä¿®å¤æœåŠ¡é…ç½®: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç»Ÿä¸€APIåŸºç¡€URLé…ç½®
            new_content = f'''/**
 * æœåŠ¡é…ç½®æ–‡ä»¶ - ç»Ÿä¸€é…ç½®
 */

// APIåŸºç¡€URL,æ ¹æ®ç¯å¢ƒè®¾ç½®
const baseUrl = process.env.NODE_ENV === 'development'
  ? '{self.unified_config["api_base_url"]}'  // å¼€å‘ç¯å¢ƒ
  : '{self.unified_config["api_base_url"]}';  // ç”Ÿäº§ç¯å¢ƒ

// è¶…æ—¶è®¾ç½®(æ¯«ç§’)
const timeout = 30000;

// é‡è¯•æ¬¡æ•°
const retryCount = 3;

// å¯¼å‡ºé…ç½®
export {{
  baseUrl,
  timeout,
  retryCount
}};'''
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            self.fixes_applied.append({
                "file": file_path,
                "action": "é‡å†™æœåŠ¡é…ç½®",
                "new_config": "ç»Ÿä¸€APIåœ°å€"
            })
            
            print(f"âœ… æœåŠ¡é…ç½®å·²ä¿®å¤")
            
        except Exception as e:
            print(f"âŒ ä¿®å¤æœåŠ¡é…ç½®å¤±è´¥: {e}")
    
    def _fix_agent_configurations(self):
        """ä¿®å¤Agenté…ç½®"""
        print("\nğŸ¤– ä¿®å¤Agenté…ç½®...")
        
        # æ£€æŸ¥Agentç­–ç•¥æ–‡ä»¶
        agent_files = [
            "auto_cleanup_trading_agent.py",
            "backend/ai/agent_system.py",
            "backend/services/auto_trader_service.py"
        ]
        
        strategy_issues = []
        
        for file_path in agent_files:
            if os.path.exists(file_path):
                issues = self._analyze_agent_file(file_path)
                strategy_issues.extend(issues)
        
        if strategy_issues:
            self.issues_found.extend(strategy_issues)
            print(f"âš ï¸ å‘ç° {len(strategy_issues)} ä¸ªAgentç­–ç•¥é—®é¢˜")
            
            # åˆ›å»ºç»Ÿä¸€ç­–ç•¥é…ç½®
            self._create_unified_strategy_config()
        else:
            print("âœ… Agenté…ç½®æ£€æŸ¥é€šè¿‡")
    
    def _analyze_agent_file(self, file_path: str) -> List[Dict]:
        """åˆ†æAgentæ–‡ä»¶"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ£€æŸ¥ç­–ç•¥å‚æ•°ç¡¬ç¼–ç 
            if "profit_pct > 10" in content:
                issues.append({
                    "file": file_path,
                    "issue": "æ­¢ç›ˆå‚æ•°ç¡¬ç¼–ç ",
                    "suggestion": "ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†ç­–ç•¥å‚æ•°"
                })
            
            # æ£€æŸ¥é£é™©æ§åˆ¶
            if "stop_loss" not in content.lower():
                issues.append({
                    "file": file_path,
                    "issue": "ç¼ºå°‘æ­¢æŸæœºåˆ¶",
                    "suggestion": "æ·»åŠ ç»Ÿä¸€çš„é£é™©æ§åˆ¶"
                })
            
        except Exception as e:
            issues.append({
                "file": file_path,
                "issue": f"æ–‡ä»¶åˆ†æå¤±è´¥: {e}",
                "suggestion": "æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œç¼–ç "
            })
        
        return issues
    
    def _create_unified_strategy_config(self):
        """åˆ›å»ºç»Ÿä¸€ç­–ç•¥é…ç½®"""
        print("ğŸ“‹ åˆ›å»ºç»Ÿä¸€ç­–ç•¥é…ç½®...")
        
        strategy_config = {
            "risk_management": {
                "max_position_size": 0.1,
                "max_daily_loss": 0.02,
                "stop_loss_pct": 0.08,
                "take_profit_pct": 0.10
            },
            "trading_rules": {
                "min_volume": 1000000,
                "max_price": 100,
                "trading_hours": {
                    "start": "09:30",
                    "end": "15:00"
                }
            },
            "strategies": {
                "momentum": {
                    "enabled": True,
                    "buy_threshold": -0.05,
                    "sell_threshold": 0.10
                },
                "mean_reversion": {
                    "enabled": True,
                    "oversold_rsi": 30,
                    "overbought_rsi": 70
                }
            }
        }
        
        config_path = "config/trading_strategy.json"
        os.makedirs("config", exist_ok=True)
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(strategy_config, f, ensure_ascii=False, indent=2)
        
        self.fixes_applied.append({
            "file": config_path,
            "action": "åˆ›å»ºç»Ÿä¸€ç­–ç•¥é…ç½®",
            "description": "é›†ä¸­ç®¡ç†æ‰€æœ‰äº¤æ˜“ç­–ç•¥å‚æ•°"
        })
        
        print(f"âœ… ç»Ÿä¸€ç­–ç•¥é…ç½®å·²åˆ›å»º: {config_path}")
    
    def _fix_deployment_configurations(self):
        """ä¿®å¤éƒ¨ç½²é…ç½®"""
        print("\nğŸš€ ä¿®å¤éƒ¨ç½²é…ç½®...")
        
        # ä¿®å¤Cloudflare Pagesé…ç½®
        self._create_cloudflare_config()
        
        # ä¿®å¤åç«¯CORSé…ç½®
        self._fix_backend_cors()
        
        # åˆ›å»ºéƒ¨ç½²è„šæœ¬
        self._create_deployment_script()
    
    def _create_cloudflare_config(self):
        """åˆ›å»ºCloudflareé…ç½®"""
        print("â˜ï¸ åˆ›å»ºCloudflare Pagesé…ç½®...")
        
        # åˆ›å»º_redirectsæ–‡ä»¶
        redirects_content = """# Cloudflare Pagesé‡å®šå‘è§„åˆ™
/api/* https://api.aigupiao.me/api/:splat 200
/* /index.html 200
"""
        
        with open("_redirects", 'w', encoding='utf-8') as f:
            f.write(redirects_content)
        
        # åˆ›å»ºwrangler.toml
        wrangler_config = """name = "aigupiao-frontend"
compatibility_date = "2023-12-01"

[env.production]
route = "app.aigupiao.me/*"

[env.development]
route = "dev.aigupiao.me/*"
"""
        
        with open("wrangler.toml", 'w', encoding='utf-8') as f:
            f.write(wrangler_config)
        
        self.fixes_applied.append({
            "file": "_redirects, wrangler.toml",
            "action": "åˆ›å»ºCloudflareé…ç½®",
            "description": "é…ç½®åŸŸåè·¯ç”±å’Œé‡å®šå‘"
        })
        
        print("âœ… Cloudflareé…ç½®å·²åˆ›å»º")
    
    def _fix_backend_cors(self):
        """ä¿®å¤åç«¯CORSé…ç½®"""
        print("ğŸ”’ ä¿®å¤åç«¯CORSé…ç½®...")
        
        cors_files = ["backend/app.py", "cloud_app.py"]
        
        for file_path in cors_files:
            if os.path.exists(file_path):
                self._update_cors_config(file_path)
    
    def _update_cors_config(self, file_path: str):
        """æ›´æ–°CORSé…ç½®"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç»Ÿä¸€CORSé…ç½®
            new_cors_config = '''# ç»Ÿä¸€CORSé…ç½®
origins = [
    "http://localhost:8080",     # å¼€å‘æœåŠ¡å™¨
    "http://localhost:3000",     # å¤‡ç”¨å¼€å‘æœåŠ¡å™¨
    "https://app.aigupiao.me",   # ä¸»åº”ç”¨åŸŸå
    "https://aigupiao.me",       # ä¸»åŸŸå
    "https://mobile.aigupiao.me", # ç§»åŠ¨ç«¯åŸŸå
    "capacitor://localhost",     # ç§»åŠ¨åº”ç”¨
    "ionic://localhost"
]'''
            
            # æ›¿æ¢ç°æœ‰CORSé…ç½®
            pattern = r'origins\s*=\s*\[[\s\S]*?\]'
            if re.search(pattern, content):
                content = re.sub(pattern, new_cors_config.split('# ç»Ÿä¸€CORSé…ç½®\n')[1], content)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                self.fixes_applied.append({
                    "file": file_path,
                    "action": "æ›´æ–°CORSé…ç½®",
                    "description": "ç»Ÿä¸€è·¨åŸŸè®¿é—®é…ç½®"
                })
                
                print(f"âœ… {file_path} CORSé…ç½®å·²æ›´æ–°")
            
        except Exception as e:
            print(f"âŒ æ›´æ–°CORSé…ç½®å¤±è´¥: {e}")
    
    def _cleanup_duplicate_files(self):
        """æ¸…ç†é‡å¤æ–‡ä»¶"""
        print("\nğŸ§¹ æ¸…ç†é‡å¤æ–‡ä»¶...")
        
        # æ£€æŸ¥é‡å¤çš„å‰ç«¯ç›®å½•
        frontend_dirs = ["frontend/gupiao1", "frontend/stock5", "ç‚’è‚¡å…»å®¶"]
        
        print("ğŸ“ æ£€æµ‹åˆ°çš„å‰ç«¯ç›®å½•:")
        for dir_path in frontend_dirs:
            if os.path.exists(dir_path):
                size = self._get_dir_size(dir_path)
                print(f"  {dir_path} - {size:.1f}MB")
        
        # å»ºè®®ä¿ç•™ä¸»è¦ç›®å½•
        print("\nğŸ’¡ å»ºè®®:")
        print("  ä¿ç•™: ç‚’è‚¡å…»å®¶ (ä¸»è¦å‰ç«¯)")
        print("  ä¿ç•™: frontend/gupiao1 (å¤‡ç”¨å‰ç«¯)")
        print("  è€ƒè™‘åˆ é™¤: frontend/stock5 (å¦‚æœåŠŸèƒ½é‡å¤)")
    
    def _get_dir_size(self, dir_path: str) -> float:
        """è·å–ç›®å½•å¤§å°(MB)"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(dir_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(filepath)
                except:
                    pass
        return total_size / (1024 * 1024)
    
    def _create_deployment_script(self):
        """åˆ›å»ºéƒ¨ç½²è„šæœ¬"""
        print("ğŸ“œ åˆ›å»ºéƒ¨ç½²è„šæœ¬...")
        
        deploy_script = '''#!/bin/bash
# é¡¹ç›®è‡ªåŠ¨éƒ¨ç½²è„šæœ¬

echo "ğŸš€ å¼€å§‹éƒ¨ç½²AIè‚¡ç¥¨äº¤æ˜“ç³»ç»Ÿ..."

# æ£€æŸ¥GitçŠ¶æ€
if [ -n "$(git status --porcelain)" ]; then
    echo "ğŸ“ æäº¤å½“å‰æ›´æ”¹..."
    git add .
    git commit -m "é…ç½®ä¿®å¤éƒ¨ç½²: $(date '+%Y-%m-%d %H:%M:%S')"
fi

# æ¨é€åˆ°GitHub
echo "ğŸ“¤ æ¨é€åˆ°GitHub..."
git push origin main

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "ğŸŒ è®¿é—®åœ°å€: https://app.aigupiao.me"
'''
        
        with open("deploy.sh", 'w', encoding='utf-8') as f:
            f.write(deploy_script)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        try:
            os.chmod("deploy.sh", 0o755)
        except:
            pass
        
        print("âœ… éƒ¨ç½²è„šæœ¬å·²åˆ›å»º: deploy.sh")
    
    def _generate_fix_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆä¿®å¤æŠ¥å‘Š...")
        
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "summary": {
                "issues_found": len(self.issues_found),
                "fixes_applied": len(self.fixes_applied),
                "backup_location": str(self.backup_dir)
            },
            "issues_found": self.issues_found,
            "fixes_applied": self.fixes_applied,
            "unified_config": self.unified_config,
            "next_steps": [
                "æµ‹è¯•å‰ç«¯APIè¿æ¥",
                "éªŒè¯Agentç­–ç•¥é…ç½®",
                "éƒ¨ç½²åˆ°Cloudflare Pages",
                "æ£€æŸ¥ç§»åŠ¨ç«¯è®¿é—®"
            ]
        }
        
        report_file = f"fix_report_{int(time.time())}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # æ˜¾ç¤ºæ‘˜è¦
        print(f"\nğŸ“‹ ä¿®å¤æ‘˜è¦:")
        print(f"  å‘ç°é—®é¢˜: {len(self.issues_found)} ä¸ª")
        print(f"  åº”ç”¨ä¿®å¤: {len(self.fixes_applied)} ä¸ª")
        print(f"  å¤‡ä»½ä½ç½®: {self.backup_dir}")
        print(f"  è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # æ˜¾ç¤ºå…³é”®ä¿®å¤
        print(f"\nğŸ”§ å…³é”®ä¿®å¤:")
        for fix in self.fixes_applied[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"  âœ… {fix['action']}: {fix['file']}")
    
    def _restore_backup(self):
        """æ¢å¤å¤‡ä»½"""
        print(f"\nğŸ”„ ä»å¤‡ä»½æ¢å¤é…ç½®...")
        try:
            if self.backup_dir.exists():
                for backup_file in self.backup_dir.rglob("*"):
                    if backup_file.is_file():
                        original_path = backup_file.relative_to(self.backup_dir)
                        shutil.copy2(backup_file, original_path)
                print(f"âœ… é…ç½®å·²ä» {self.backup_dir} æ¢å¤")
            else:
                print("âŒ å¤‡ä»½ç›®å½•ä¸å­˜åœ¨")
        except Exception as e:
            print(f"âŒ æ¢å¤å¤‡ä»½å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    fixer = ProjectConfigurationFixer()
    
    print("ğŸ¯ é¡¹ç›®é…ç½®ä¿®å¤å·¥å…·")
    print("=" * 30)
    print("æ­¤å·¥å…·å°†ä¿®å¤:")
    print("1. å‰ç«¯APIåœ°å€é…ç½®ä¸ä¸€è‡´")
    print("2. Agentç­–ç•¥é…ç½®åˆ†æ•£")
    print("3. éƒ¨ç½²é…ç½®ä¸å®Œæ•´")
    print("4. é‡å¤æ–‡ä»¶æ¸…ç†")
    print()
    
    confirm = input("æ˜¯å¦å¼€å§‹ä¿®å¤ï¼Ÿ(y/N): ")
    if confirm.lower() == 'y':
        fixer.run_comprehensive_fix()
    else:
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")

if __name__ == "__main__":
    main()
