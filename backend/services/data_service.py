import pandas as pd
import numpy as np
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union
import logging
import requests
from pathlib import Path

logger = logging.getLogger(__name__)

# æ•°æ®ç¼“å­˜
data_cache = {}

def get_historical_data(symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
    """
    è·å–å†å²æ•°æ®
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        
    Returns:
        DataFrame: åŒ…å«æ—¥æœŸ,å¼€ç›˜ä»·,æœ€é«˜ä»·,æœ€ä½ä»·,æ”¶ç›˜ä»·,æˆäº¤é‡çš„æ•°æ®æ¡†
    """
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"{symbol}_{start_date}_{end_date}"
    if cache_key in data_cache:
        return data_cache[cache_key]
    
    try:
        # å°è¯•ä»æœ¬åœ°æ–‡ä»¶è¯»å–
        data = _load_from_local(symbol, start_date, end_date)
        
        if data is None:
            # å¦‚æœæœ¬åœ°æ²¡æœ‰,ä»è¿œç¨‹APIè·å–
            data = _fetch_from_remote(symbol, start_date, end_date)
            
            # ä¿å­˜åˆ°æœ¬åœ°
            if data is not None:
                _save_to_local(symbol, data)
        
        # ç¼“å­˜æ•°æ®
        if data is not None:
            data_cache[cache_key] = data
            
        return data
        
    except Exception as e:
        logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºå¼€å‘å’Œæµ‹è¯•
        return _create_sample_data(symbol, start_date, end_date)

def _load_from_local(symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ•°æ®"""
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    file_path = Path(f"backend/data/historical/{symbol}.csv")
    
    if not file_path.exists():
        return None
    
    try:
        # è¯»å–CSVæ–‡ä»¶
        df = pd.read_csv(file_path)
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯æ—¥æœŸç±»å‹å¹¶è®¾ä¸ºç´¢å¼•
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
        
        # è¿‡æ»¤æ—¥æœŸèŒƒå›´
        start = pd.to_datetime(start_date)
        end = pd.to_datetime(end_date)
        df = df[(df.index >= start) & (df.index <= end)]
        
        if df.empty:
            return None
            
        return df
        
    except Exception as e:
        logger.error(f"ä»æœ¬åœ°åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None

def _fetch_from_remote(symbol: str, start_date: str, end_date: str) -> Optional[pd.DataFrame]:
    """ä»è¿œç¨‹APIè·å–æ•°æ®"""
    # è¿™é‡Œåº”å½“å®ç°ä¸å®é™…æ•°æ®APIçš„é›†æˆ
    # ä¾‹å¦‚: è°ƒç”¨Yahoo Finance,Alpha Vantageç­‰
    
    # ç¤ºä¾‹: ä½¿ç”¨Yahoo Finance API
    try:
        # è½¬æ¢æ—¥æœŸæ ¼å¼ (YYYY-MM-DD -> UNIXæ—¶é—´æˆ³)
        start_timestamp = int(datetime.strptime(start_date, "%Y-%m-%d").timestamp())
        end_timestamp = int(datetime.strptime(end_date, "%Y-%m-%d").timestamp())
        
        # æ„é€ APIè¯·æ±‚URL (ç¤ºä¾‹)
        url = f"https://query1.finance.yahoo.com/v7/finance/download/{symbol}"
        params = {
            "period1": start_timestamp,
            "period2": end_timestamp,
            "interval": "1d",
            "events": "history",
            "includeAdjustedClose": "true"
        }
        
        # å‘é€è¯·æ±‚
        # response = requests.get(url, params=params)
        
        # å¦‚æœAPIè¯·æ±‚æˆåŠŸ
        # if response.status_code == 200:
        #     # è§£æCSVæ•°æ®
        #     data = pd.read_csv(StringIO(response.text))
        #     data['Date'] = pd.to_datetime(data['Date'])
        #     data.set_index('Date', inplace=True)
        #     
        #     # é‡å‘½ååˆ—åä»¥åŒ¹é…æˆ‘ä»¬çš„æ ‡å‡†
        #     data.rename(columns={
        #         'Open': 'open',
        #         'High': 'high',
        #         'Low': 'low',
        #         'Close': 'close',
        #         'Volume': 'volume'
        #     }, inplace=True)
        #     
        #     return data
        
        # å¼€å‘é˜¶æ®µè¿”å›æ¨¡æ‹Ÿæ•°æ®
        return _create_sample_data(symbol, start_date, end_date)
        
    except Exception as e:
        logger.error(f"ä»è¿œç¨‹è·å–æ•°æ®å¤±è´¥: {e}")
        return None

def _save_to_local(symbol: str, data: pd.DataFrame) -> bool:
    """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶"""
    try:
        # åˆ›å»ºç›®å½•
        os.makedirs("backend/data/historical", exist_ok=True)
        
        # ä¿å­˜åˆ°CSV
        file_path = f"backend/data/historical/{symbol}.csv"
        data.reset_index().to_csv(file_path, index=False)
        
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®åˆ°æœ¬åœ°å¤±è´¥: {e}")
        return False

def _create_sample_data(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    ğŸš¨ ç¦ç”¨ç¤ºä¾‹æ•°æ®åˆ›å»º - åªå…è®¸çœŸå®æ•°æ®
    """
    error_msg = f"""
    âŒ é”™è¯¯ï¼šç³»ç»Ÿç¦æ­¢åˆ›å»ºç¤ºä¾‹æ•°æ®

    è¯·æ±‚çš„è‚¡ç¥¨: {symbol}
    æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}

    è¯·é…ç½®çœŸå®æ•°æ®æºï¼š
    1. æ·˜å®è‚¡ç¥¨æ•°æ®æ¨é€æœåŠ¡ (API_KEY: QT_wat5QfcJ6N9pDZM5)
    2. åŒèŠ±é¡ºå®æ—¶æ•°æ®API
    3. é€šè¾¾ä¿¡æ•°æ®æ¥å£

    ç³»ç»Ÿæ‹’ç»æä¾›ä»»ä½•æ¨¡æ‹Ÿæˆ–ç¤ºä¾‹æ•°æ®ï¼
    """

    logger.error(error_msg)
    raise ValueError(error_msg)

def get_available_symbols() -> List[Dict[str, str]]:
    """è·å–å¯ç”¨çš„è‚¡ç¥¨åˆ—è¡¨"""
    # ç¤ºä¾‹åˆ—è¡¨
    symbols = [
        {"symbol": "AAPL", "name": "Apple Inc.", "market": "ç¾å›½"},
        {"symbol": "MSFT", "name": "Microsoft Corporation", "market": "ç¾å›½"},
        {"symbol": "GOOGL", "name": "Alphabet Inc.", "market": "ç¾å›½"},
        {"symbol": "AMZN", "name": "Amazon.com Inc.", "market": "ç¾å›½"},
        {"symbol": "TSLA", "name": "Tesla, Inc.", "market": "ç¾å›½"},
        {"symbol": "600519.SS", "name": "è´µå·èŒ…å°", "market": "ä¸­å›½"},
        {"symbol": "000651.SZ", "name": "æ ¼åŠ›ç”µå™¨", "market": "ä¸­å›½"},
        {"symbol": "000333.SZ", "name": "ç¾çš„é›†å›¢", "market": "ä¸­å›½"},
        {"symbol": "601318.SS", "name": "ä¸­å›½å¹³å®‰", "market": "ä¸­å›½"},
        {"symbol": "600036.SS", "name": "æ‹›å•†é“¶è¡Œ", "market": "ä¸­å›½"}
    ]
    
    return symbols 
