#!/usr/bin/env python3
"""
æ•´åˆä¾èµ–åŒ…ç®¡ç†
è§£å†³å¤šä¸ªrequirements.txtæ–‡ä»¶å†²çª
"""

import os
import shutil
from datetime import datetime
from pathlib import Path

class DependencyFixer:
    """ä¾èµ–åŒ…ç®¡ç†ä¿®å¤å™¨"""
    
    def __init__(self):
        self.backup_dir = f"deps_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    def fix_dependencies(self):
        """ä¿®å¤ä¾èµ–åŒ…ç®¡ç†"""
        print("ğŸ“¦ æ•´åˆä¾èµ–åŒ…ç®¡ç†")
        print("=" * 50)
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        os.makedirs(self.backup_dir, exist_ok=True)
        
        # 1. æ”¶é›†æ‰€æœ‰requirementsæ–‡ä»¶
        req_files = self._collect_requirements_files()
        
        # 2. åˆå¹¶ä¾èµ–åŒ…
        merged_deps = self._merge_dependencies(req_files)
        
        # 3. åˆ›å»ºç»Ÿä¸€çš„requirementsæ–‡ä»¶
        self._create_unified_requirements(merged_deps)
        
        # 4. æ¸…ç†é‡å¤æ–‡ä»¶
        self._cleanup_duplicate_files(req_files)
        
        print(f"\nâœ… ä¾èµ–åŒ…ç®¡ç†æ•´åˆå®Œæˆï¼")
        print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¿å­˜åœ¨: {self.backup_dir}")
        
    def _collect_requirements_files(self):
        """æ”¶é›†æ‰€æœ‰requirementsæ–‡ä»¶"""
        print("\nğŸ” æ”¶é›†requirementsæ–‡ä»¶...")
        
        req_files = []
        search_patterns = [
            "requirements.txt",
            "backend/requirements.txt", 
            "backend/requirements_supabase.txt",
            "requirements_cloud.txt",
            "requirements_local.txt"
        ]
        
        for pattern in search_patterns:
            if os.path.exists(pattern):
                req_files.append(pattern)
                print(f"  ğŸ“„ å‘ç°: {pattern}")
        
        return req_files
    
    def _merge_dependencies(self, req_files):
        """åˆå¹¶ä¾èµ–åŒ…"""
        print("\nğŸ”§ åˆå¹¶ä¾èµ–åŒ…...")
        
        all_deps = {}
        
        for req_file in req_files:
            print(f"  ğŸ“– å¤„ç†: {req_file}")
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_name = req_file.replace("/", "_").replace("\\", "_") + ".backup"
            shutil.copy2(req_file, os.path.join(self.backup_dir, backup_name))
            
            try:
                with open(req_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        # è§£æåŒ…åå’Œç‰ˆæœ¬
                        if '==' in line:
                            pkg_name, version = line.split('==', 1)
                        elif '>=' in line:
                            pkg_name, version = line.split('>=', 1)
                            version = f">={version}"
                        else:
                            pkg_name = line
                            version = ""
                        
                        pkg_name = pkg_name.strip()
                        
                        # å¤„ç†ç‰ˆæœ¬å†²çª
                        if pkg_name in all_deps:
                            existing_version = all_deps[pkg_name]
                            if existing_version != version and version:
                                print(f"    âš ï¸ ç‰ˆæœ¬å†²çª: {pkg_name} ({existing_version} vs {version})")
                                # é€‰æ‹©æ›´ä¸¥æ ¼çš„ç‰ˆæœ¬ï¼ˆ==ä¼˜äº>=ï¼‰
                                if '==' in version:
                                    all_deps[pkg_name] = version
                                elif '==' not in existing_version:
                                    all_deps[pkg_name] = version
                        else:
                            all_deps[pkg_name] = version
                            
            except Exception as e:
                print(f"    âŒ å¤„ç†å¤±è´¥: {e}")
        
        print(f"  âœ… åˆå¹¶å®Œæˆï¼Œå…± {len(all_deps)} ä¸ªåŒ…")
        return all_deps
    
    def _create_unified_requirements(self, merged_deps):
        """åˆ›å»ºç»Ÿä¸€çš„requirementsæ–‡ä»¶"""
        print("\nğŸ“ åˆ›å»ºç»Ÿä¸€requirementsæ–‡ä»¶...")
        
        # æŒ‰ç±»åˆ«ç»„ç»‡ä¾èµ–åŒ…
        categories = {
            "web_framework": ["fastapi", "uvicorn", "starlette", "pydantic"],
            "database": ["supabase", "psycopg2", "psycopg2-binary", "sqlalchemy"],
            "http_client": ["requests", "httpx", "aiohttp"],
            "data_processing": ["pandas", "numpy", "redis"],
            "windows_api": ["pywin32", "win32gui", "win32api"],
            "websocket": ["websockets", "python-socketio"],
            "utilities": ["python-dotenv", "schedule", "asyncio"],
            "development": ["pytest", "black", "flake8"]
        }
        
        # åˆ›å»ºä¸»requirementsæ–‡ä»¶
        main_requirements = []
        main_requirements.append("# æ™ºèƒ½äº¤æ˜“ç³»ç»Ÿ - ç»Ÿä¸€ä¾èµ–åŒ…é…ç½®")
        main_requirements.append(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}")
        main_requirements.append("")
        
        # æŒ‰ç±»åˆ«æ·»åŠ ä¾èµ–
        for category, packages in categories.items():
            category_deps = []
            for pkg in packages:
                if pkg in merged_deps:
                    version = merged_deps[pkg]
                    if version:
                        category_deps.append(f"{pkg}{version}")
                    else:
                        category_deps.append(pkg)
                    # ä»merged_depsä¸­ç§»é™¤å·²å¤„ç†çš„åŒ…
                    del merged_deps[pkg]
            
            if category_deps:
                main_requirements.append(f"# {category.replace('_', ' ').title()}")
                main_requirements.extend(category_deps)
                main_requirements.append("")
        
        # æ·»åŠ å…¶ä»–æœªåˆ†ç±»çš„åŒ…
        if merged_deps:
            main_requirements.append("# å…¶ä»–ä¾èµ–")
            for pkg, version in sorted(merged_deps.items()):
                if version:
                    main_requirements.append(f"{pkg}{version}")
                else:
                    main_requirements.append(pkg)
            main_requirements.append("")
        
        # å†™å…¥ä¸»requirementsæ–‡ä»¶
        with open("requirements.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(main_requirements))
        
        print("âœ… å·²åˆ›å»º: requirements.txt")
        
        # åˆ›å»ºå¼€å‘ç¯å¢ƒrequirements
        dev_requirements = [
            "# å¼€å‘ç¯å¢ƒé¢å¤–ä¾èµ–",
            "pytest>=7.0.0",
            "black>=22.0.0",
            "flake8>=4.0.0",
            "mypy>=0.950",
            "pre-commit>=2.17.0",
            ""
        ]
        
        with open("requirements-dev.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(dev_requirements))
        
        print("âœ… å·²åˆ›å»º: requirements-dev.txt")
        
        # åˆ›å»ºç”Ÿäº§ç¯å¢ƒrequirements
        prod_requirements = [
            "# ç”Ÿäº§ç¯å¢ƒä¾èµ–ï¼ˆåŸºäºä¸»requirementsï¼‰",
            "-r requirements.txt",
            "",
            "# ç”Ÿäº§ç¯å¢ƒç‰¹å®šåŒ…",
            "gunicorn>=20.1.0",
            "supervisor>=4.2.0",
            ""
        ]
        
        with open("requirements-prod.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(prod_requirements))
        
        print("âœ… å·²åˆ›å»º: requirements-prod.txt")
    
    def _cleanup_duplicate_files(self, req_files):
        """æ¸…ç†é‡å¤æ–‡ä»¶"""
        print("\nğŸ§¹ æ¸…ç†é‡å¤æ–‡ä»¶...")
        
        # ä¿ç•™ä¸»requirements.txtï¼Œç§»é™¤å…¶ä»–æ–‡ä»¶
        for req_file in req_files:
            if req_file != "requirements.txt":
                try:
                    os.remove(req_file)
                    print(f"  ğŸ—‘ï¸ å·²åˆ é™¤: {req_file}")
                except Exception as e:
                    print(f"  âŒ åˆ é™¤å¤±è´¥ {req_file}: {e}")
        
        # åˆ›å»ºä¾èµ–ç®¡ç†è¯´æ˜æ–‡ä»¶
        readme_content = """# ä¾èµ–åŒ…ç®¡ç†è¯´æ˜

## æ–‡ä»¶è¯´æ˜

- `requirements.txt` - ä¸»è¦ä¾èµ–åŒ…ï¼ŒåŒ…å«æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ‰€éœ€çš„åŒ…
- `requirements-dev.txt` - å¼€å‘ç¯å¢ƒé¢å¤–ä¾èµ–ï¼ŒåŒ…å«æµ‹è¯•ã€ä»£ç æ ¼å¼åŒ–ç­‰å·¥å…·
- `requirements-prod.txt` - ç”Ÿäº§ç¯å¢ƒä¾èµ–ï¼ŒåŸºäºä¸»requirementså¹¶æ·»åŠ ç”Ÿäº§ç¯å¢ƒç‰¹å®šåŒ…

## å®‰è£…è¯´æ˜

### å¼€å‘ç¯å¢ƒ
```bash
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### ç”Ÿäº§ç¯å¢ƒ
```bash
pip install -r requirements-prod.txt
```

### è™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ–
venv\\Scripts\\activate  # Windows

pip install -r requirements.txt
```

## ç»´æŠ¤è¯´æ˜

1. æ–°å¢ä¾èµ–æ—¶ï¼Œè¯·æ·»åŠ åˆ° `requirements.txt` å¹¶æŒ‡å®šç‰ˆæœ¬å·
2. å¼€å‘å·¥å…·ä¾èµ–è¯·æ·»åŠ åˆ° `requirements-dev.txt`
3. å®šæœŸæ›´æ–°ä¾èµ–åŒ…ç‰ˆæœ¬ï¼Œç¡®ä¿å®‰å…¨æ€§
4. ä½¿ç”¨ `pip freeze > requirements-freeze.txt` ç”Ÿæˆç²¾ç¡®ç‰ˆæœ¬å¿«ç…§

## ç‰ˆæœ¬ç®¡ç†

- ä½¿ç”¨ `==` å›ºå®šç‰ˆæœ¬å·ç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§
- å…³é”®ä¾èµ–åŒ…å¿…é¡»æŒ‡å®šç‰ˆæœ¬
- å®šæœŸæ£€æŸ¥åŒ…çš„å®‰å…¨æ›´æ–°
"""
        
        with open("DEPENDENCIES.md", 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        print("âœ… å·²åˆ›å»ºä¾èµ–ç®¡ç†è¯´æ˜: DEPENDENCIES.md")

if __name__ == "__main__":
    fixer = DependencyFixer()
    fixer.fix_dependencies()
